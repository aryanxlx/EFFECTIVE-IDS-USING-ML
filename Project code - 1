{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499760e9-d80e-4792-8252-01c0a79a065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e37892-33ec-46ce-a4db-001c06fafe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df75599-30a4-4834-9aa6-0901cb511da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>proto</th>\n",
       "      <th>flow_FIN_flag_count</th>\n",
       "      <th>fwd_PSH_flag_count</th>\n",
       "      <th>bwd_pkts_payload.max</th>\n",
       "      <th>bwd_pkts_payload.min</th>\n",
       "      <th>fwd_pkts_payload.std</th>\n",
       "      <th>bwd_pkts_payload.std</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_bulk_rate</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.00000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>1.231170e+05</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "      <td>123117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.556446</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.101732</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>36.466548</td>\n",
       "      <td>2.813129</td>\n",
       "      <td>6.415648</td>\n",
       "      <td>18.446862</td>\n",
       "      <td>131.21166</td>\n",
       "      <td>1.433996</td>\n",
       "      <td>3.242938e+04</td>\n",
       "      <td>124.525107</td>\n",
       "      <td>2586.788892</td>\n",
       "      <td>2.829617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.601466</td>\n",
       "      <td>0.232121</td>\n",
       "      <td>0.433786</td>\n",
       "      <td>3.277407</td>\n",
       "      <td>167.733587</td>\n",
       "      <td>14.423564</td>\n",
       "      <td>35.635970</td>\n",
       "      <td>84.776842</td>\n",
       "      <td>153.89866</td>\n",
       "      <td>2.182864</td>\n",
       "      <td>4.454864e+05</td>\n",
       "      <td>276.435192</td>\n",
       "      <td>9356.314472</td>\n",
       "      <td>2.471211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>4013.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>639.223507</td>\n",
       "      <td>880.644172</td>\n",
       "      <td>4013.00000</td>\n",
       "      <td>276.833333</td>\n",
       "      <td>2.488969e+07</td>\n",
       "      <td>40637.333330</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             service          proto  flow_FIN_flag_count  fwd_PSH_flag_count  \\\n",
       "count  123117.000000  123117.000000        123117.000000       123117.000000   \n",
       "mean        0.556446       0.056247             0.101732            0.304840   \n",
       "std         1.601466       0.232121             0.433786            3.277407   \n",
       "min         0.000000       0.000000             0.000000            0.000000   \n",
       "25%         0.000000       0.000000             0.000000            0.000000   \n",
       "50%         0.000000       0.000000             0.000000            0.000000   \n",
       "75%         0.000000       0.000000             0.000000            0.000000   \n",
       "max         9.000000       2.000000            10.000000          753.000000   \n",
       "\n",
       "       bwd_pkts_payload.max  bwd_pkts_payload.min  fwd_pkts_payload.std  \\\n",
       "count         123117.000000         123117.000000         123117.000000   \n",
       "mean              36.466548              2.813129              6.415648   \n",
       "std              167.733587             14.423564             35.635970   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max             4013.000000            548.000000            639.223507   \n",
       "\n",
       "       bwd_pkts_payload.std  flow_pkts_payload.max  fwd_subflow_pkts  \\\n",
       "count         123117.000000           123117.00000     123117.000000   \n",
       "mean              18.446862              131.21166          1.433996   \n",
       "std               84.776842              153.89866          2.182864   \n",
       "min                0.000000                0.00000          0.000000   \n",
       "25%                0.000000              120.00000          1.000000   \n",
       "50%                0.000000              120.00000          1.000000   \n",
       "75%                0.000000              120.00000          1.000000   \n",
       "max              880.644172             4013.00000        276.833333   \n",
       "\n",
       "       bwd_bulk_rate  fwd_subflow_bytes  bwd_init_window_size    Attack_type  \n",
       "count   1.231170e+05      123117.000000         123117.000000  123117.000000  \n",
       "mean    3.242938e+04         124.525107           2586.788892       2.829617  \n",
       "std     4.454864e+05         276.435192           9356.314472       2.471211  \n",
       "min     0.000000e+00           0.000000              0.000000       0.000000  \n",
       "25%     0.000000e+00         120.000000              0.000000       2.000000  \n",
       "50%     0.000000e+00         120.000000              0.000000       2.000000  \n",
       "75%     0.000000e+00         120.000000              0.000000       2.000000  \n",
       "max     2.488969e+07       40637.333330          65535.000000      11.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ccff29-099f-4a1d-a647-1f31c51189f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = data.values\n",
    "X = array[:,0:]\n",
    "y = array[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73acd14-007f-4dc2-a234-f06fef10c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['service','proto','flow_FIN_flag_count','fwd_PSH_flag_count','bwd_pkts_payload.max','bwd_pkts_payload.min','fwd_pkts_payload.std','bwd_pkts_payload.std','flow_pkts_payload.max','fwd_subflow_pkts','bwd_bulk_rate','fwd_subflow_bytes','bwd_init_window_size','Attack_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8110f976-ad3e-48fc-a1ee-9bcf23f7d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd50999-d9f4-456c-8bc0-91f199d8a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f058efc-cd57-4d06-afb9-4ac536da796f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41516270-3184-4cfa-989b-11527373e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5744e9fe-1115-40f8-829c-d43beb972b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997292614251678\n",
      "Precision: 0.9997311552481201\n",
      "Recall: 0.9997292614251678\n",
      "True Positives (TP): 36926\n",
      "True Negatives (TN): -10\n",
      "False Positives (FP): 10\n",
      "False Negatives (FN): 10\n",
      "Confusion Matrix:\n",
      " [[ 2365     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0   162     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 28436     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     1     8     0     0     1     0     0     0     0     0]\n",
      " [    0     0     0     0  1229     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     4     6     0     0     0     0     0]\n",
      " [    0     0     0     0     1     0   616     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   287     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0   751     1     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0   592     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0  2394     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_jobs=-1, random_state=15)\n",
    "\n",
    "# Train the Random Forest classifier using training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbeddb2-8690-427e-bd9a-92ea69e0696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Mean Accuracy: 0.85, Std Deviation: 0.00\n",
      "Repetition 2: Mean Accuracy: 0.85, Std Deviation: 0.00\n",
      "Repetition 3: Mean Accuracy: 0.85, Std Deviation: 0.00\n",
      "Repetition 4: Mean Accuracy: 0.85, Std Deviation: 0.00\n"
     ]
    }
   ],
   "source": [
    "#10x4 VALIDATION-------------> Random Forest\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa6629a-a9b4-4a01-82da-d2f6346b29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f925e3bf-9599-4273-84a7-dfb29433808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8654700021659086\n",
      "Precision: 0.7833446550745623\n",
      "Recall: 0.8654700021659086\n",
      "True Positives (TP): 31967\n",
      "True Negatives (TN): -4969\n",
      "False Positives (FP): 4969\n",
      "False Negatives (FN): 4969\n",
      "Confusion Matrix:\n",
      " [[    0     0  2365     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0   162     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 28238     0   129     0    68     1     0     0     0     0]\n",
      " [    0     0     2     0     5     0     0     0     1     2     0     0]\n",
      " [    0     0   259     5   752     0     1     5    60     8   139     0]\n",
      " [    0     0     1     0     7     0     0     0     1     1     0     0]\n",
      " [    0     0    27     0    68     0     1     0   507     4    10     0]\n",
      " [    0     0     3     0     0     0     0     0   282     0     2     0]\n",
      " [    0     0     0     0     1     0     0     0   749     0     2     0]\n",
      " [    0     0    28     0    12     0     0     0   283     1   268     0]\n",
      " [    0     0    95     0    58     0     0     0     8     7  2226     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0    82     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the Logistic Regression classifier\n",
    "logistic_regression = LogisticRegression(random_state=15, solver='liblinear')\n",
    "\n",
    "# Train the Logistic Regression classifier using training data\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = logistic_regression.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23a1c3d-a5ef-4cc8-ab68-16bba124df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Mean Accuracy: 0.77, Std Deviation: 0.00\n",
      "Repetition 2: Mean Accuracy: 0.77, Std Deviation: 0.00\n",
      "Repetition 3: Mean Accuracy: 0.77, Std Deviation: 0.00\n",
      "Repetition 4: Mean Accuracy: 0.77, Std Deviation: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#10x4 validation ------> Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression  # Import Logistic Regression, replace with your desired model\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f4b966-4249-4664-b279-ac5bca75a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49356bbc-cb24-46b6-b64a-8c42fe0f01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1846437080355209\n",
      "Precision: 0.5191580505127366\n",
      "Recall: 0.1846437080355209\n",
      "True Positives (TP): 6820\n",
      "True Negatives (TN): -30116\n",
      "False Positives (FP): 30116\n",
      "False Negatives (FN): 30116\n",
      "Confusion Matrix:\n",
      " [[ 2365     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [  162     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [24707     0  3616     9     3    11    64     0    12     2    12     0]\n",
      " [    1     0     2     3     0     3     0     0     1     0     0     0]\n",
      " [    0     0   698     0   205     9    31     0    98    39   149     0]\n",
      " [    1     0     1     0     0     4     0     0     2     1     1     0]\n",
      " [    7     0   284     3     1    27   265     0     9     2    19     0]\n",
      " [    0     0   141     0     0     0   105     0    39     0     2     0]\n",
      " [    0     0   384     0     0     1   175     0   186     0     6     0]\n",
      " [    5     0   285     0    18    12   184     0    79     1     8     0]\n",
      " [ 1195     0   781     6   111     7    18     0    40    61   175     0]\n",
      " [   82     0     0     0     0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier using training data\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = naive_bayes.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a778a1-0dc4-431e-b8ee-15a727140bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Mean Accuracy: 0.18, Std Deviation: 0.00\n",
      "Repetition 2: Mean Accuracy: 0.18, Std Deviation: 0.00\n",
      "Repetition 3: Mean Accuracy: 0.18, Std Deviation: 0.00\n",
      "Repetition 4: Mean Accuracy: 0.18, Std Deviation: 0.00\n"
     ]
    }
   ],
   "source": [
    "#10x4 validation ------> Naive Bayes\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB  # Import Gaussian Naive Bayes, replace with your desired model\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = GaussianNB()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d671f88-40d0-45fc-9890-741ac169c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d068000-48b2-4bd3-8edd-0e30d4b7aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7aa71fb-bd37-490b-abf1-ed5e87b21306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875730994152047\n",
      "Precision: 0.9874493105444557\n",
      "Recall: 0.9875730994152047\n",
      "True Positives (TP): 36477\n",
      "True Negatives (TN): -459\n",
      "False Positives (FP): 459\n",
      "False Negatives (FN): 459\n",
      "Confusion Matrix:\n",
      " [[ 2365     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0   162     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 28400     1    17     0     6     1     2     6     3     0]\n",
      " [    0     0     8     0     1     0     0     0     0     1     0     0]\n",
      " [    0     0     8     0  1126     0     1     1    15     4    74     0]\n",
      " [    0     0     5     0     1     0     3     0     0     0     1     0]\n",
      " [    0     0    21     2     9     1   578     0     0     3     3     0]\n",
      " [    0     0     0     0     5     0     2   251    25     4     0     0]\n",
      " [    0     0     0     0     7     0     1     6   723    14     1     0]\n",
      " [    0     0     2     0     1     0     0     4    41   543     1     0]\n",
      " [    0     0     3     0   137     0     1     1     3     2  2247     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNeighborsClassifier using training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "589707fb-dcc7-4b49-94e5-49f375a104ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Mean Accuracy: 0.16, Std Deviation: 0.00\n",
      "Repetition 2: Mean Accuracy: 0.16, Std Deviation: 0.00\n",
      "Repetition 3: Mean Accuracy: 0.16, Std Deviation: 0.00\n",
      "Repetition 4: Mean Accuracy: 0.16, Std Deviation: 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Import KNN classifier, replace with your desired model\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579d4832-28dd-4bc4-9253-dd3d328cd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4bfa1f-506e-4431-b872-2c87822cd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Convert the float labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86066cd6-bb08-4cc6-854e-965e4bae75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999729261425168\n",
      "Precision: 0.9999729270945812\n",
      "Recall: 0.9999729261425168\n",
      "True Positives (TP): 36935\n",
      "True Negatives (TN): -1\n",
      "False Positives (FP): 1\n",
      "False Negatives (FN): 1\n",
      "Confusion Matrix:\n",
      " [[ 2365     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0   162     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 28436     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0    10     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0  1229     0     0     0     0     0     0     0]\n",
      " [    0     0     1     0     0     9     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   617     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   287     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0   752     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0   592     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0  2394     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    82]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the XGBoost classifier using training data\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d623cd-fbbd-48a5-a67b-f6c8e03b5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10x4 XGBOOST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier  # Import XGBoost classifier, replace with your desired model\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee171d3-d7f1-4f75-91ce-9e5c60ccf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAR REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7446e70-188b-4552-9d13-5f5b3fd325df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error for Linear Regression:\", mse)\n",
    "print(\"R-squared (Coefficient of Determination) for Linear Regression:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747145af-f1da-4a94-a21a-def244391652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'target' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define k-fold cross-validation with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores to positive since sklearn returns negative MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean MSE: {np.mean(cv_scores):.2f}\")\n",
    "print(f\"Standard Deviation of MSE: {np.std(cv_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ca876-bd3b-49bb-ae80-80b13b129c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71e815-906d-465b-b1e6-3b584a18b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c897f5-2426-428e-8cd0-42c2d6b038be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "\n",
    "# Train the Decision Tree classifier using training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = decision_tree.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2dc0c-a6de-4b3d-90a2-ba0f779241e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') \n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  \n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  \n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8991c-b8a6-4e04-a027-0298fb32561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7437c3a-9f67-45af-8c0b-e5d554e4dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "# Train the model\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273fbda-7e3c-4e28-9ee8-5c258aad56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate the Support Vector Classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the SVC classifier using training data\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_test = svc_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "# Confusion Matrix\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "# Extract TP, TN, FP, FN from confusion matrix\n",
    "TP = np.diag(CM).sum()\n",
    "FP = CM.sum(axis=0).sum() - TP\n",
    "FN = CM.sum(axis=1).sum() - TP\n",
    "TN = CM.sum().sum() - (TP + FP + FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397443a7-ae15-45a8-b70c-da94f7d13335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC  # Import SVC classifier, replace with your desired model\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('E:/project/ref.csv') #reading csv file\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Attack_type'])  # Assuming 'Attack_type' is the target variable\n",
    "y = data['Attack_type']\n",
    "\n",
    "# Define the model (replace with your desired model)\n",
    "model = SVC()\n",
    "\n",
    "# Define 10-fold cross-validation with 4 repetitions\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 10 folds\n",
    "repetitions = 4\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = []\n",
    "for i in range(repetitions):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "    cv_results.append(cv_scores)\n",
    "\n",
    "# Convert the list of arrays into a numpy array for easier manipulation\n",
    "cv_results = np.array(cv_results)\n",
    "\n",
    "# Print the results\n",
    "for i in range(repetitions):\n",
    "    print(f\"Repetition {i+1}: Mean Accuracy: {np.mean(cv_results[i]):.2f}, Std Deviation: {np.std(cv_results[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff623d1a-d847-4d0c-8aa3-dcae095d1632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6058e-b875-408e-8441-82c0178d2442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b3931-e895-4161-a1d6-942686bf8879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0c108-ffc7-45d7-86f8-ac2506df02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3083a85-fe09-41e9-a0d3-de0cce1bb467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6020c9a-df2a-452f-8f62-34904a5d1db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01105af7-5054-4fc1-b34c-6dc509352ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c4518-e4f2-43a3-9bbc-0a85f6d59974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd786bb-4208-426a-aa0c-c09da6e08602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e259310-c917-4f24-9579-253fd5cba52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce9754-e6ef-4795-879c-fdcdaa990431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de529d5-8ce1-4ef6-a426-446d5bdad5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5faa5-a732-40ad-9854-5b4c31958ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
